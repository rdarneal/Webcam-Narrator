{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook will outline the end to end overview of setting up the elevenlabs voice model, to utilizing the voice model to describe images recorded via openCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outline\n",
    "1. Train a voice model\n",
    "2. Process and store images via webcam\n",
    "3. Evaluate images via OpenAI\n",
    "4. Narrate images via ElevenLabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precursor - Download and prepare audio from youtube (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# yt-dlp requires ffmpeg, https://ffmpeg.org/\n",
    "!python -m pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# download an audio file from youtube as an mp3\n",
    "!yt-dlp -x --audio-format mp3 --audio-quality 196K -o \"audio.%(ext)s\" https://www.youtube.com/watch?v=GGoCBAo9N_g\n",
    "!rm -rf audio.webm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# extract 3 min from the mp3\n",
    "!ffmpeg -i audio.mp3 -ss 300 -t 180 out.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Prepare dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "import errno\n",
    "import time\n",
    "import pandas as pd\n",
    "from elevenlabs import Voice, VoiceSettings, play, stream\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv()) # load .env file to be used with os.getenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train a voice model\n",
    "- Prepare files for training\n",
    "- Conduct training\n",
    "- Verify output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate client session with elevenlabs.io\n",
    "el_client = ElevenLabs(\n",
    "\tapi_key=os.getenv(\"ELEVEN_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple voice clone\n",
    "voice = el_client.clone(\n",
    "\tname=\"SaDa\",\n",
    "\tdescription=\"A voice purely for test purposes internally, not to be distributed\",\n",
    "\tfiles=[\"out.mp3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing and selecting available voices (Elevenlabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the available voices\n",
    "response = el_client.voices.get_all()\n",
    "json_response = json.loads(response.json())\n",
    "data_to_load = json_response['voices']\n",
    "jdf = pd.DataFrame(data_to_load)\n",
    "jdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the labels column into new columns of the original dataframe\n",
    "labels_keys = set()\n",
    "for labels in jdf['labels']:\n",
    "\tlabels_keys.update(labels.keys())\n",
    "for key in labels_keys:\n",
    "\tjdf[key] = jdf['labels'].apply(lambda x: x.get(key, None))\n",
    "jdf.drop('labels', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simplified list of available voices\n",
    "df = jdf[['voice_id','name','description','accent','age','use case','gender']].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_voice = df.iloc[46]['voice_id']\n",
    "select_voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating voice content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = el_client.generate(\n",
    "\ttext=\"This is a test\",\n",
    "\tvoice=select_voice,\n",
    "\tstream=True\n",
    ")\n",
    "stream(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the voice ID as the argument for running main.py\n",
    "print(select_voice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
